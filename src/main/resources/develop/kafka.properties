## 消费者配置信息
bootstrap.servers=192.168.0.10:9092
# 消费者群组ID，如果一个生产者，多个消费者都要消费，那么需要定义自己的群组，同一群组内的消费者只有一个能消费到消息
group.id=group1
# 连接zk的 session 超时时间
zookeeper.session.timeout.ms=400
# zk follower 落后于 zk leader 的最长时间
zookeeper.sync.time.ms=200
# 往 zookeeper 上写 offset 的频率
auto.commit.interval.ms=1000
# 当各分区下有已提交的 offset 时，从提交的offset开始消费；无提交的 offset 时，从头开始消费
auto.offset.reset=earliest
# key 序列化
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
# value 序列化
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

## 生产者配置信息
# 首领在返回确认或错误响应之前，会等待所有同步副本都收到消息。
acks=all
# 消息发送失败后的重试次数
retries=0
# 每个Batch要存放batch.size大小的数据后，才可以发送出去
batch.size=16384
# 一个Batch被创建之后，最多过多久，不管这个Batch有没有写满，都必须发送出去了。
linger.ms=1
# 决定了每次发送给Kafka服务器请求消息的最大大小。
buffer.memory=33554432
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer